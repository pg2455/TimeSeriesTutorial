{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c31b75a0-3c13-4513-9d5b-46cc4d4fc4aa",
   "metadata": {},
   "source": [
    "# Time Series Datasets Using GluonTS Library\n",
    "\n",
    "In this notebook, we will explore the GluonTS library, a Python library designed for time series modeling with a focus on deep learning models, based on PyTorch and MXNet.\n",
    "\n",
    "While we will develop models using this library later in the series, this notebook aims to familiarize ourselves with GluonTS's dataset loading capabilities.\n",
    "\n",
    "Library documentation: [GluonTS Documentation](https://ts.gluon.ai/stable/index.html#)\n",
    "\n",
    "## Installation\n",
    "\n",
    "Install the library by running the following command in your shell:\n",
    "\n",
    "```bash\n",
    "pip install gluonts\n",
    "```\n",
    "\n",
    "## Dataset Loading with GluonTS\n",
    "\n",
    "GluonTS provides the `gluonts.dataset` package ([documentation](https://ts.gluon.ai/stable/api/gluonts/gluonts.dataset.html)), which includes a subpackage `gluonts.dataset.repository` for downloading commonly available datasets.\n",
    "\n",
    "### Available Datasets\n",
    "\n",
    "You can view the list of available datasets in the [source code](https://ts.gluon.ai/stable/_modules/gluonts/dataset/repository/datasets.html#get_download_path) or by accessing the `dataset_names` variable in the subpackage. Many of these datasets are similar to those we have explored in previous notebooks.\n",
    "\n",
    "For example, to download the Traffic dataset, use the corresponding key - 'traffic'.\n",
    "\n",
    "**Note:** The first download may take some time as the dataset is stored in `$HOME/.gluonts`. Subsequent accesses will check this directory before downloading again.\n",
    "\n",
    "### GluonTS vs. Loading Your Own Data\n",
    "\n",
    "GluonTS applies preprocessing to the datasets and specifies meta information about train-test splits. You can review this preprocessing by examining the specific loading functions in the source code. For instance, the \"traffic\" dataset follows the preprocessing defined in `generate_lstnet_dataset` ([source code link](https://github.com/jgasthaus/gluon-ts/blob/c47ac9a0e11439edb9bdaae80975fefd035ae595/src/gluonts/dataset/repository/_lstnet.py#L125)). This function indicates that the dataset will be loaded for `rolling_evaluations=7`, resulting in 7 time series with incrementally larger horizons for model evaluation.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c76a46cd-4975-41d2-920d-26714eaec8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utils_tfb # copied a specific function to read data\n",
    "from gluonts.dataset.repository.datasets import get_dataset, dataset_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed6714a6-eaaf-47fb-bd99-9c4cb0a5faed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available datasets:  ['constant', 'exchange_rate', 'solar-energy', 'electricity', 'traffic', 'exchange_rate_nips', 'electricity_nips', 'traffic_nips', 'solar_nips', 'wiki2000_nips', 'wiki-rolling_nips', 'taxi_30min', 'kaggle_web_traffic_with_missing', 'kaggle_web_traffic_without_missing', 'kaggle_web_traffic_weekly', 'm1_yearly', 'm1_quarterly', 'm1_monthly', 'nn5_daily_with_missing', 'nn5_daily_without_missing', 'nn5_weekly', 'tourism_monthly', 'tourism_quarterly', 'tourism_yearly', 'cif_2016', 'london_smart_meters_without_missing', 'wind_farms_without_missing', 'car_parts_without_missing', 'dominick', 'fred_md', 'pedestrian_counts', 'hospital', 'covid_deaths', 'kdd_cup_2018_without_missing', 'weather', 'm3_monthly', 'm3_quarterly', 'm3_yearly', 'm3_other', 'm4_hourly', 'm4_daily', 'm4_weekly', 'm4_monthly', 'm4_quarterly', 'm4_yearly', 'm5', 'uber_tlc_daily', 'uber_tlc_hourly', 'airpassengers', 'australian_electricity_demand', 'electricity_hourly', 'electricity_weekly', 'rideshare_without_missing', 'saugeenday', 'solar_10_minutes', 'solar_weekly', 'sunspot_without_missing', 'temperature_rain_without_missing', 'vehicle_trips_without_missing', 'ercot', 'ett_small_15min', 'ett_small_1h']\n"
     ]
    }
   ],
   "source": [
    "print(\"Available datasets: \", dataset_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac1f265-0b95-4aa8-836f-cdef88ebbb75",
   "metadata": {},
   "source": [
    "## Download & Load Traffic Dataset\n",
    "\n",
    "The **Traffic dataset** is a multivariate dataset containing 48 months (2015-2016) of hourly data from the California Department of Transportation. It includes road occupancy rates (values between 0 and 1) measured by various sensors on San Francisco Bay area freeways. This dataset was first utilized by Lai et al. (2017) to evaluate the performance of different modeling techniques.\n",
    "\n",
    "[[1] Lai et al. 2017, Modeling Long- and Short-Term Temporal Patterns with Deep Neural Networks](https://arxiv.org/abs/1703.07015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad39782e-8c0e-43ab-8570-ff4ac2d6112b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_dataset(\"traffic\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b431e5a1-6c41-40c5-b0b3-97e6d1561348",
   "metadata": {},
   "source": [
    "**Metadata**:\n",
    "GluonTS datasets come with metadata that provide specific information about the time series, including:\n",
    "\n",
    "- **Frequency of Data:** Indicates the time interval of the data points (e.g., hourly 'H', monthly 'M').\n",
    "- **Prediction Length:** Specifies the forecasting horizon.\n",
    "- **Cardinality:** The number of time series in the dataset (1 for univariate datasets).\n",
    "- **Exogenous Variables:** Details about any additional variables present in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "398ac95c-b3a1-4b3b-9a7f-f72dd31677f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MetaData(freq='H', target=None, feat_static_cat=[CategoricalFeatureInfo(name='feat_static_cat_0', cardinality='862')], feat_static_real=[], feat_dynamic_real=[], feat_dynamic_cat=[], prediction_length=24)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2638dfa4-7f9e-489c-bac9-dfe0a0acab12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of the dataset: H\n",
      "Prediction horizon: 24\n"
     ]
    }
   ],
   "source": [
    "freq = dataset.metadata.freq\n",
    "prediction_length = dataset.metadata.prediction_length\n",
    "\n",
    "print(f\"Frequency of the dataset: {freq}\")\n",
    "print(f\"Prediction horizon: {prediction_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d34715-0d8c-4924-98d0-edcc64ba3d26",
   "metadata": {},
   "source": [
    "## Training Dataset\n",
    "\n",
    "GluonTS provides methods to organize and split time series datasets into subsets for training machine learning models. Let's explore how GluonTS handles these datasets.\n",
    "\n",
    "The time series data is organized in a GluonTS dataset as follows\n",
    "\n",
    "- **'target':** Each dimension (multivariate has multiple dimensions) is represented as a 1D numpy array.\n",
    "- **'start':** Contains information about the starting point and the period of the observations.\n",
    "- **'item_id':** The identifier of the feature or dimension.\n",
    "- **'feat_static_cat':** Contains the index of the feature or dimension in a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "18348af7-f02f-4b45-adc5-9d9f86ef60d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of time series (dimensions) in the training dataset: 862\n",
      "Number of time steps in time series in the training dataset: 14036\n",
      "An example of a time series\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'target': array([0.0048, 0.0072, 0.004 , ..., 0.053 , 0.0533, 0.05  ], dtype=float32),\n",
       " 'start': Period('2015-01-01 00:00', 'h'),\n",
       " 'feat_static_cat': array([0], dtype=int32),\n",
       " 'item_id': 0}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_dim = len(dataset.train)\n",
    "n_steps_training = next(iter(dataset.train))['target'].shape[0]\n",
    "\n",
    "print(f\"Number of time series (dimensions) in the training dataset: {n_dim}\")\n",
    "print(f\"Number of time steps in time series in the training dataset: {n_steps_training}\")\n",
    "\n",
    "print(\"An example of a time series\")\n",
    "next(iter(dataset.train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa4ad14-df19-416f-9583-fa868c1ed32f",
   "metadata": {},
   "source": [
    "## Test Dataset\n",
    "\n",
    "Following Lai et al. (2017), the forecasting task involves making hourly predictions for a day. The dataset is split into 7 test series to evaluate the estimator on these series, using the training set as input to the model.\n",
    "\n",
    "The structure of the test dataset will become clearer when we create our own custom dataset below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c00c227-2cf8-4a3b-8f2e-73293dd824cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of time series in the test dataset: 6034\n",
      "Unique time horizons in the test dataset: {14084, 14180, 14204, 14156, 14060, 14132, 14108}\n",
      "An example of a time series\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'target': array([0.0048, 0.0072, 0.004 , ..., 0.0467, 0.0412, 0.0386], dtype=float32),\n",
       " 'start': Period('2015-01-01 00:00', 'H'),\n",
       " 'feat_static_cat': array([0], dtype=int32),\n",
       " 'item_id': 0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Number of time series in the test dataset: {len(dataset.test)}\")\n",
    "\n",
    "lens = set()\n",
    "for x in iter(dataset.test):\n",
    "    lens.add(x['target'].shape[0])\n",
    "\n",
    "print(\"Unique time horizons in the test dataset:\", lens)\n",
    "\n",
    "print(\"An example of a time series\")\n",
    "next(iter(dataset.test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774a4904-8c84-41b5-adbe-77b8e482fdcb",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "\n",
    "How is a dataset split into training and testing sets? We will look at the train-test splitting process in the forecasting notebook.\n",
    "\n",
    "## Custom Datasets with GluonTS\n",
    "\n",
    "We can also import our own datasets into the GluonTS format. Let's take an example of a raw dataset without a clear definition of frequency.\n",
    "\n",
    "Specifically, we will use the `economics_97.csv` dataset we downloaded earlier in the `forecasting` folder, which lacks a defined time index. Let's load this dataset into GluonTS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7acf4a0f-a55b-453a-8b67-96ee367e7aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "TS_DATA_FOLDER = pathlib.Path(\"./forecasting\").resolve()\n",
    "dataset = TS_DATA_FOLDER / \"economics_97.csv\"\n",
    "data = utils_tfb.read_data(str(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf62d81e-cea4-42cf-b9d0-23f8d1f5c8c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00.000000001</th>\n",
       "      <td>38.396118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00.000000002</th>\n",
       "      <td>32.301302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00.000000003</th>\n",
       "      <td>28.912815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00.000000004</th>\n",
       "      <td>31.747465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00.000000005</th>\n",
       "      <td>38.663177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00.000000068</th>\n",
       "      <td>30.995002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00.000000069</th>\n",
       "      <td>35.926088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00.000000070</th>\n",
       "      <td>30.613136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00.000000071</th>\n",
       "      <td>28.850088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00.000000072</th>\n",
       "      <td>31.928914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               channel_1\n",
       "date                                    \n",
       "1970-01-01 00:00:00.000000001  38.396118\n",
       "1970-01-01 00:00:00.000000002  32.301302\n",
       "1970-01-01 00:00:00.000000003  28.912815\n",
       "1970-01-01 00:00:00.000000004  31.747465\n",
       "1970-01-01 00:00:00.000000005  38.663177\n",
       "...                                  ...\n",
       "1970-01-01 00:00:00.000000068  30.995002\n",
       "1970-01-01 00:00:00.000000069  35.926088\n",
       "1970-01-01 00:00:00.000000070  30.613136\n",
       "1970-01-01 00:00:00.000000071  28.850088\n",
       "1970-01-01 00:00:00.000000072  31.928914\n",
       "\n",
       "[72 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4801848-6899-4f9f-91b1-dade2b9af49e",
   "metadata": {},
   "source": [
    "**Note:** The date column has a frequency of `nanoseconds`, while we expect yearly measurements for this dataset. Let's clean this up and load it into GluonTS.\n",
    "\n",
    "For this example, we'll assume the following:\n",
    "\n",
    "1. **Prediction Length:** The forecasting horizon we care about, e.g., predicting 4 years ahead.\n",
    "2. **Rolling Windows:** Determines how many evaluations we need to perform to set up the correct evaluation metric.\n",
    "\n",
    "The rolling window approach suggests that for each evaluation of time series metrics, we use the historical data within the window to make predictions for the specified forecasting horizon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b47b72a2-8049-4a5a-8b95-d0e91338f5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dl/lib/python3.10/site-packages/gluonts/dataset/common.py:255: FutureWarning: 'Y' is deprecated and will be removed in a future version, please use 'YE' instead.\n",
      "  ProcessDataEntry(to_offset(freq), one_dim_target, use_timestamp),\n"
     ]
    }
   ],
   "source": [
    "from gluonts.dataset.common import ListDataset\n",
    "\n",
    "freq = '1Y'\n",
    "start = pd.Period(\"01-01-1990\", freq=freq)\n",
    "prediction_length = 4\n",
    "rolling_windows = 6\n",
    "\n",
    "train_ds = ListDataset(\n",
    "    [{\n",
    "        \"target\": data['channel_1'].values[:-rolling_windows*prediction_length], \"start\": start\n",
    "    }],\n",
    "    freq=freq\n",
    ")\n",
    "\n",
    "test_ds = ListDataset(\n",
    "    [\n",
    "        {\n",
    "            \"target\": data['channel_1'].values[:-(rolling_windows - x - 1) * prediction_length], \"start\": start\n",
    "        } \n",
    "    for x in range(rolling_windows)],\n",
    "    freq=freq\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b436dd6e-fc8d-4267-86b9-05bbc163cb49",
   "metadata": {},
   "source": [
    "**Note:** The test dataset is organized as an iterable due to the rolling window approach. We will explore this concept in more detail in the next notebook on forecasting.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Proceed to the next notebook (`02_forecasting_basics.ipynb`) to formally understand forecasting basics and how to perform time series splitting for model development."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
