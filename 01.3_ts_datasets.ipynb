{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e01d374-6dde-4c5c-b699-5b586d4d99e0",
   "metadata": {},
   "source": [
    "# Time Series Datasets: GluonTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177bb38b-9933-4335-b1b5-a35ca190281f",
   "metadata": {},
   "source": [
    "In this notebook, we will look at a python library, GluonTS, that is a python library for time series modeling, with a focus on deep learning based models, based on PyTorch and MXNet.\n",
    "\n",
    "We will use the library to develop models later in the series. However, this notebook is only to get ourselves familiar with the dataset loading capability of GluonTS. \n",
    "\n",
    "Library documentation: [https://ts.gluon.ai/](https://ts.gluon.ai/stable/index.html#)\n",
    "\n",
    "Let's install the library! Run the following command in your shell - \n",
    "\n",
    "```bash\n",
    "pip install \"gluonts\"\n",
    "```\n",
    "\n",
    "`gluonts` provides a package named `gluonts.dataset` [documentation](https://ts.gluon.ai/stable/api/gluonts/gluonts.dataset.html). We will use a subpackage of `gluonts.dataset` named `gluonts.dataset.repository` to download several commonly available datasets online. \n",
    "\n",
    "Which datasets are available in the package? We can look at the list of available datasets in the [source code] (https://ts.gluon.ai/stable/_modules/gluonts/dataset/repository/datasets.html#get_download_path) or `dataset_names` variable from the subpackage. Most of these datasets are similar to what we have been looking at in the previous notebooks. \n",
    "\n",
    "For example, if we have to download the Traffic [1] dataset, we can use the corresponding key. \n",
    "\n",
    "**Note:** It may take some time to download the dataset in `$HOME/.gluonts` for the first time. From the next time, it looks for the dataset in `$HOME/.gluonts` before downloading.\n",
    "\n",
    "\n",
    "**GluonTS vs Loading your own data**\n",
    "\n",
    "Note: GluonTS applies its preprocessing on the datasets as well as specifies some meta information about train-test splits. One can get this information by reading the specific loading functions used in the source code. For example, \"traffic\" data follows the preprocessing specified here in `generate_lstnet_dataset` ([link](https://github.com/jgasthaus/gluon-ts/blob/c47ac9a0e11439edb9bdaae80975fefd035ae595/src/gluonts/dataset/repository/_lstnet.py#L125)). From the source code, one can infer that the dataset will be loaded for `rolling_evaluations=7` as a result, we should expect 7 time series of incremetally larger horizons for evluating our models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df1e6da-f6d4-4d2e-8361-e9f3922e81cc",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c76a46cd-4975-41d2-920d-26714eaec8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utils_tfb # copied a specific function to read data\n",
    "from gluonts.dataset.repository.datasets import get_dataset, dataset_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed6714a6-eaaf-47fb-bd99-9c4cb0a5faed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available datasets:  ['constant', 'exchange_rate', 'solar-energy', 'electricity', 'traffic', 'exchange_rate_nips', 'electricity_nips', 'traffic_nips', 'solar_nips', 'wiki2000_nips', 'wiki-rolling_nips', 'taxi_30min', 'kaggle_web_traffic_with_missing', 'kaggle_web_traffic_without_missing', 'kaggle_web_traffic_weekly', 'm1_yearly', 'm1_quarterly', 'm1_monthly', 'nn5_daily_with_missing', 'nn5_daily_without_missing', 'nn5_weekly', 'tourism_monthly', 'tourism_quarterly', 'tourism_yearly', 'cif_2016', 'london_smart_meters_without_missing', 'wind_farms_without_missing', 'car_parts_without_missing', 'dominick', 'fred_md', 'pedestrian_counts', 'hospital', 'covid_deaths', 'kdd_cup_2018_without_missing', 'weather', 'm3_monthly', 'm3_quarterly', 'm3_yearly', 'm3_other', 'm4_hourly', 'm4_daily', 'm4_weekly', 'm4_monthly', 'm4_quarterly', 'm4_yearly', 'm5', 'uber_tlc_daily', 'uber_tlc_hourly', 'airpassengers', 'australian_electricity_demand', 'electricity_hourly', 'electricity_weekly', 'rideshare_without_missing', 'saugeenday', 'solar_10_minutes', 'solar_weekly', 'sunspot_without_missing', 'temperature_rain_without_missing', 'vehicle_trips_without_missing', 'ercot', 'ett_small_15min', 'ett_small_1h']\n"
     ]
    }
   ],
   "source": [
    "print(\"Available datasets: \", dataset_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac1f265-0b95-4aa8-836f-cdef88ebbb75",
   "metadata": {},
   "source": [
    "## Download & Load Traffic Dataset\n",
    "\n",
    "**Traffic dataset**: A multivariate dataset containing a collection of 48 months (2015-2016) hourly data from the California Department of Transportation. The data contains the road occupancy rates (value between 0 and 1) measured by different senosrs on San Francisco Bay area freeways. This dataset was first used by Lai et al. (2017) for someone to look further into what mdeling techniques perform how on these datasets.\n",
    "\n",
    "[[1] Lai et al. 2017 Modeling Long- and Short-Term Temporal Patterns with Deep Neural Networks](https://arxiv.org/abs/1703.07015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad39782e-8c0e-43ab-8570-ff4ac2d6112b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_dataset(\"traffic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001986d3-047b-4272-a7d6-54ba7e014df7",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b480abe8-2c20-4e29-9b31-bf1b0cfe3eb5",
   "metadata": {},
   "source": [
    "GluonTS Datasets have their metadata that contain information about the specifics of the time series, such as the \n",
    "- frequency of data (hourly 'H', monthly 'M', etc.)\n",
    "- prediction length for the forecasting horizon,\n",
    "- cardinality: number of time series in the dataset (1 for univariate dataset)\n",
    "- Other exogenous variables, if present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "398ac95c-b3a1-4b3b-9a7f-f72dd31677f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MetaData(freq='H', target=None, feat_static_cat=[CategoricalFeatureInfo(name='feat_static_cat_0', cardinality='862')], feat_static_real=[], feat_dynamic_real=[], feat_dynamic_cat=[], prediction_length=24)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2638dfa4-7f9e-489c-bac9-dfe0a0acab12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of the dataset: H\n",
      "Prediction horizon: 24\n"
     ]
    }
   ],
   "source": [
    "freq = dataset.metadata.freq\n",
    "prediction_length = dataset.metadata.prediction_length\n",
    "\n",
    "print(f\"Frequency of the dataset: {freq}\")\n",
    "print(f\"Prediction horizon: {prediction_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d34715-0d8c-4924-98d0-edcc64ba3d26",
   "metadata": {},
   "source": [
    "## Training Dataset\n",
    "\n",
    "GluonTS has methods to present time series and split them into subsets for training estimators / machine learning models. \n",
    "Let's look at how GluonTS presents these datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "18348af7-f02f-4b45-adc5-9d9f86ef60d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of time series (dimensions) in the training dataset: 862\n",
      "Number of time steps in time series in the training dataset: 14036\n",
      "An example of a time series\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'target': array([0.0048, 0.0072, 0.004 , ..., 0.053 , 0.0533, 0.05  ], dtype=float32),\n",
       " 'start': Period('2015-01-01 00:00', 'h'),\n",
       " 'feat_static_cat': array([0], dtype=int32),\n",
       " 'item_id': 0}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_dim = len(dataset.train)\n",
    "n_steps_training = next(iter(dataset.train))['target'].shape[0]\n",
    "\n",
    "print(f\"Number of time series (dimensions) in the training dataset: {n_dim}\")\n",
    "print(f\"Number of time steps in time series in the training dataset: {n_steps_training}\")\n",
    "\n",
    "print(\"An example of a time series\")\n",
    "next(iter(dataset.train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733bc757-327d-47c7-9a96-a488ec7956f4",
   "metadata": {},
   "source": [
    "Here is how time series data is arranged in the dataset - \n",
    "\n",
    "- 'target': Each dimension (multivariate has multiple dimensions) is represented as a 1D numpy array\n",
    "- 'start': It contains information about the starting point and the period of the observations\n",
    "- 'item_id': It's the id of the feature or dimension.\n",
    "- 'feat_static_cat': it contains the index of the feature or dimension in a numpy array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa4ad14-df19-416f-9583-fa868c1ed32f",
   "metadata": {},
   "source": [
    "## Test Dataset\n",
    "\n",
    "Following Lai et al. (2017), the forecasting task is to make hourly predictions for a day. The dataset has been split into 7 test series to assess the estimator on seven test series, such that the input to the model is training set.\n",
    "\n",
    "The arrangement of test dataset into an iterable will become more clear when we create our own custom dataset below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c00c227-2cf8-4a3b-8f2e-73293dd824cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of time series in the test dataset: 6034\n",
      "Unique time horizons in the test dataset: {14084, 14180, 14204, 14156, 14060, 14132, 14108}\n",
      "An example of a time series\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'target': array([0.0048, 0.0072, 0.004 , ..., 0.0467, 0.0412, 0.0386], dtype=float32),\n",
       " 'start': Period('2015-01-01 00:00', 'H'),\n",
       " 'feat_static_cat': array([0], dtype=int32),\n",
       " 'item_id': 0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Number of time series in the test dataset: {len(dataset.test)}\")\n",
    "\n",
    "lens = set()\n",
    "for x in iter(dataset.test):\n",
    "    lens.add(x['target'].shape[0])\n",
    "\n",
    "print(\"Unique time horizons in the test dataset:\", lens)\n",
    "\n",
    "print(\"An example of a time series\")\n",
    "next(iter(dataset.test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfeaeca-2843-4e0f-8280-3a9409542b0a",
   "metadata": {},
   "source": [
    "## Train-Test split\n",
    "\n",
    "Given a dataset, how is this train-test split done? We will learn more about splitting in the notebook on forecasting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c6a219-beeb-4799-b7d3-a801f7f89ba8",
   "metadata": {},
   "source": [
    "## Custom Datasets with GluonTS\n",
    "\n",
    "We can also import our datasets in GLuonTS format.\n",
    "\n",
    "We will take an example of a raw dataset with no clear definition of frequency.\n",
    "\n",
    "Specfically, the dataset we downloaded earlier in `forecasting` folder contains `economics_97.csv` with no clear definition of the time index. Let's load that dataset in GluonTS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7acf4a0f-a55b-453a-8b67-96ee367e7aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "TS_DATA_FOLDER = pathlib.Path(\"./forecasting\").resolve()\n",
    "dataset = TS_DATA_FOLDER / \"economics_97.csv\"\n",
    "data = utils_tfb.read_data(str(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf62d81e-cea4-42cf-b9d0-23f8d1f5c8c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00.000000001</th>\n",
       "      <td>38.396118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00.000000002</th>\n",
       "      <td>32.301302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00.000000003</th>\n",
       "      <td>28.912815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00.000000004</th>\n",
       "      <td>31.747465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00.000000005</th>\n",
       "      <td>38.663177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00.000000068</th>\n",
       "      <td>30.995002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00.000000069</th>\n",
       "      <td>35.926088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00.000000070</th>\n",
       "      <td>30.613136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00.000000071</th>\n",
       "      <td>28.850088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00.000000072</th>\n",
       "      <td>31.928914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               channel_1\n",
       "date                                    \n",
       "1970-01-01 00:00:00.000000001  38.396118\n",
       "1970-01-01 00:00:00.000000002  32.301302\n",
       "1970-01-01 00:00:00.000000003  28.912815\n",
       "1970-01-01 00:00:00.000000004  31.747465\n",
       "1970-01-01 00:00:00.000000005  38.663177\n",
       "...                                  ...\n",
       "1970-01-01 00:00:00.000000068  30.995002\n",
       "1970-01-01 00:00:00.000000069  35.926088\n",
       "1970-01-01 00:00:00.000000070  30.613136\n",
       "1970-01-01 00:00:00.000000071  28.850088\n",
       "1970-01-01 00:00:00.000000072  31.928914\n",
       "\n",
       "[72 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4801848-6899-4f9f-91b1-dade2b9af49e",
   "metadata": {},
   "source": [
    "**Note:** You can see that the date column has a frequency of `nanoseconds`, wereas we expect this dataset to be yearly measurement of metrics in economics. Let's clean that up and load that in GluonTS.\n",
    "\n",
    "Just for an example, we need to assume the following -- \n",
    "\n",
    "1. Prediction Length: This is the forecasting horizon which we care about. Let's we care about predicting 4 years ahead.\n",
    "2. Rolling windows: This determines how mnay evaluations we need to do to setup the right metric.\n",
    "\n",
    "Rolling window suggests that for every evaluation of time series metrics, we look at the historical data determined by it, and then make predictions about the forecasting horizon determined by the prediction length. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b47b72a2-8049-4a5a-8b95-d0e91338f5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dl/lib/python3.10/site-packages/gluonts/dataset/common.py:255: FutureWarning: 'Y' is deprecated and will be removed in a future version, please use 'YE' instead.\n",
      "  ProcessDataEntry(to_offset(freq), one_dim_target, use_timestamp),\n"
     ]
    }
   ],
   "source": [
    "from gluonts.dataset.common import ListDataset\n",
    "\n",
    "freq = '1Y'\n",
    "start = pd.Period(\"01-01-1990\", freq=freq)\n",
    "prediction_length = 4\n",
    "rolling_windows = 6\n",
    "\n",
    "train_ds = ListDataset(\n",
    "    [{\n",
    "        \"target\": data['channel_1'].values[:-rolling_windows*prediction_length], \"start\": start\n",
    "    }],\n",
    "    freq=freq\n",
    ")\n",
    "\n",
    "test_ds = ListDataset(\n",
    "    [\n",
    "        {\n",
    "            \"target\": data['channel_1'].values[:-(rolling_windows - x - 1) * prediction_length], \"start\": start\n",
    "        } \n",
    "    for x in range(rolling_windows)],\n",
    "    freq=freq\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6281e2d-b7b6-4ab0-9ed8-abf91fce6b10",
   "metadata": {},
   "source": [
    "As we see that the test dataset is an iterable due to a rolling window. We will learn more about this in the next notebook on forecasting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c984280-ee26-4daf-a777-85a097712220",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Now, move onto the next notebook to formally understand Forecasting, basics and how to do time series splitting for model development."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
